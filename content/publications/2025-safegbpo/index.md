+++
title = 'Leveraging Analytic Gradients in Provably Safe Reinforcement Learning'
conference = 'IEEE Open Journal of Control Systems 2025'
date = 2025-09-09
authors = [ 'Tim Walter', 'Hannah Markgraf', 'Jonathan KÃ¼lz', 'Matthias Althoff' ]
cover1 = 'cover.jpg'
bibtex = 'walter2025safegbpo.bib'

[[links]]
name = 'Project'
url = 'https://timwalter.github.io/safe-agb-rl.github.io'

[[links]]
name = 'Paper'
url = 'https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11154003'

[[links]]
name = 'Code'
url = 'https://github.com/TimWalter/SafeGBPO'

+++
With SafeGBPO we developed the first effective safeguard for analytic gradient-based reinforcement learning. We analysed existing, differentiable safeguards, adapted them through modified mappings and gradient formulations, and integrated them into a state-of-the-art learning algorithm and a differentiable simulation. 
